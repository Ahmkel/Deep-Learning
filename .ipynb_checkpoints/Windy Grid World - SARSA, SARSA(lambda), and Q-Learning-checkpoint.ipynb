{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains my implementation of SARSA, SARSA(lambda), and Q-Learning to solve the Windy Grid World problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Windy Grid World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x67bea6dcc0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAEACAYAAADRH+8yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x67bea6dd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "mdp = Image.open('./windygridworld.PNG', 'r')\n",
    "plt.axis('off')\n",
    "plt.imshow(mdp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARSA_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Representation of wind for each column\n",
    "wind = np.array([0, 0, 0, 1, 1, 1, 2, 2, 1, 0])\n",
    "\n",
    "num_episodes = 2000\n",
    "n, m = 7, 10\n",
    "initial_state = (3, 0)\n",
    "goal_state = (3, 7)\n",
    "\n",
    "rewards = np.zeros((n,m)) - 1\n",
    "rewards[goal_state] = 1\n",
    "\n",
    "# Actions\n",
    "actions = ['N', 'S', 'W', 'E', 'NW', 'NE', 'SW', 'SE']\n",
    "action_idx = {action:idx for idx,action in enumerate(actions)}\n",
    "action_effect = {\n",
    "    'N': [-1, 0],\n",
    "    'S': [1, 0],\n",
    "    'W': [0, -1],\n",
    "    'E': [0, 1],\n",
    "    'NW': [-1, -1],\n",
    "    'NE': [-1, 1],\n",
    "    'SW': [1, -1],\n",
    "    'SE': [1, 1],\n",
    "}\n",
    "\n",
    "#Policy implicitly represented in the Q values\n",
    "def get_next_action(Q, state, mode='epsilon_greedy', epsilon = 0.1):\n",
    "    optimal_action = actions[np.argmax(Q[state])]\n",
    "    random_action = actions[np.random.randint(0, len(actions))]\n",
    "    if mode == 'epsilon_greedy' and np.random.random_sample() < epsilon:\n",
    "        return random_action\n",
    "    return optimal_action\n",
    "\n",
    "def get_next_state(state, action):\n",
    "    next_state = np.sum([state, action_effect[action]], axis = 0)\n",
    "    next_state[0] = min(max(next_state[0], 0), n-1)\n",
    "    next_state[1] = min(max(next_state[1], 0), m-1)\n",
    "    next_state[0] -= wind[next_state[1]]\n",
    "    next_state[0] = min(max(next_state[0], 0), n-1)\n",
    "    return tuple(next_state)\n",
    "    \n",
    "def Q_learning(num_episodes=2000, epsilon=1.0, learning_rate = 0.05):\n",
    "    Q = np.zeros((n, m, 8))\n",
    "    episode_tenth = np.ceil(num_episodes/10)\n",
    "    for episode in range(num_episodes):\n",
    "        state = initial_state\n",
    "        i=0\n",
    "        while state!=goal_state:\n",
    "            action = get_next_action(Q=Q, state=state, mode='epsilon_greedy', epsilon=epsilon)\n",
    "            next_state = get_next_state(state=state, action=action)\n",
    "            next_action = get_next_action(Q=Q, state=next_state, mode='optimal')\n",
    "            Q[state][action_idx[action]] += learning_rate * (rewards[state] + Q[next_state][action_idx[next_action]] - Q[state][action_idx[action]])\n",
    "            state = next_state\n",
    "        epsilon *= 0.9\n",
    "        if episode % episode_tenth == 0:\n",
    "            print(episode)\n",
    "    print(episode)\n",
    "    return Q\n",
    "\n",
    "def SARSA(num_episodes=2000, epsilon=1.0, learning_rate = 0.05):\n",
    "    Q = np.zeros((n,m,8))\n",
    "    episode_tenth = np.ceil(num_episodes/10)\n",
    "    for episode in range(num_episodes):\n",
    "        state = initial_state\n",
    "        while state != goal_state:\n",
    "            action = get_next_action(Q=Q, state=state, mode='epsilon_greedy', epsilon=epsilon)\n",
    "            next_state = get_next_state(state=state, action=action)\n",
    "            next_action = get_next_action(Q=Q, state=next_state, mode='epsilon_greedy', epsilon=epsilon)\n",
    "            Q[state][action_idx[action]] += learning_rate * (rewards[state] + Q[next_state][action_idx[next_action]] - Q[state][action_idx[action]])\n",
    "            state = next_state\n",
    "        epsilon *= 0.99\n",
    "        if episode % episode_tenth == 0:\n",
    "            print(episode)\n",
    "    print(episode)\n",
    "    return Q\n",
    "\n",
    "def SARSA_lambda(num_episodes=2000, epsilon=0.5, Y=0.0, learning_rate=0.05):\n",
    "    Q = np.zeros((n,m,8))\n",
    "    episode_tenth = np.ceil(num_episodes/10)\n",
    "    for episode in range(num_episodes):\n",
    "        E = np.zeros((n,m,8))\n",
    "        state = initial_state\n",
    "        while state!=goal_state:\n",
    "            action = get_next_action(Q=Q, state=state, mode='epsilon_greedy', epsilon=epsilon)\n",
    "            next_state = get_next_state(state=state, action=action)\n",
    "            next_action = get_next_action(Q=Q, state=next_state, mode='epsilon_greedy', epsilon=epsilon)\n",
    "            G = rewards[state] + Q[next_state][action_idx[next_action]] - Q[state][action_idx[action]]\n",
    "            E[state][action_idx[action]] += 1\n",
    "            Q += learning_rate * G * E\n",
    "            E *= Y\n",
    "            state = next_state\n",
    "        epsilon *= 0.99\n",
    "        if episode % episode_tenth == 0:\n",
    "            print(episode)\n",
    "    print(episode)\n",
    "    return Q,E\n",
    "\n",
    "def perform_optimal_policy(Q):\n",
    "    s = initial_state\n",
    "    i = 0\n",
    "    grid = np.zeros((n,m))\n",
    "    grid[s] = 1\n",
    "    while s!=goal_state and i < 100 :\n",
    "        a = get_next_action(Q, s, 'optimal')\n",
    "        print('State: ', s)\n",
    "        print('Action: ', a)\n",
    "        print('-----')\n",
    "        s = get_next_state(s, a)\n",
    "        grid[s]=1\n",
    "        i+=1\n",
    "    print(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "1999\n",
      "State:  (3, 0)\n",
      "Action:  SE\n",
      "-----\n",
      "State:  (4, 1)\n",
      "Action:  SE\n",
      "-----\n",
      "State:  (5, 2)\n",
      "Action:  SE\n",
      "-----\n",
      "State:  (5, 3)\n",
      "Action:  SE\n",
      "-----\n",
      "State:  (5, 4)\n",
      "Action:  SE\n",
      "-----\n",
      "State:  (5, 5)\n",
      "Action:  SE\n",
      "-----\n",
      "State:  (4, 6)\n",
      "Action:  SE\n",
      "-----\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  1.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "Q = SARSA(num_episodes=2000, epsilon=1.0)\n",
    "perform_optimal_policy(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "1999\n",
      "State:  (3, 0)\n",
      "Action:  SE\n",
      "-----\n",
      "State:  (4, 1)\n",
      "Action:  SE\n",
      "-----\n",
      "State:  (5, 2)\n",
      "Action:  SE\n",
      "-----\n",
      "State:  (5, 3)\n",
      "Action:  SE\n",
      "-----\n",
      "State:  (5, 4)\n",
      "Action:  SE\n",
      "-----\n",
      "State:  (5, 5)\n",
      "Action:  SE\n",
      "-----\n",
      "State:  (4, 6)\n",
      "Action:  SE\n",
      "-----\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  1.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "Q,E = SARSA_lambda(num_episodes=2000, epsilon=1.0, Y=0.3)\n",
    "perform_optimal_policy(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "1999\n",
      "State:  (3, 0)\n",
      "Action:  SE\n",
      "-----\n",
      "State:  (4, 1)\n",
      "Action:  SE\n",
      "-----\n",
      "State:  (5, 2)\n",
      "Action:  SE\n",
      "-----\n",
      "State:  (5, 3)\n",
      "Action:  SE\n",
      "-----\n",
      "State:  (5, 4)\n",
      "Action:  SE\n",
      "-----\n",
      "State:  (5, 5)\n",
      "Action:  SE\n",
      "-----\n",
      "State:  (4, 6)\n",
      "Action:  SE\n",
      "-----\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  1.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "Q = Q_learning(num_episodes=2000)\n",
    "perform_optimal_policy(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [(3, 0), 'E', -1.0, (3, 1), 'NE']\n",
      "0\n",
      "1 [(3, 0), 'NE', -1.0, (2, 1), 'E']\n",
      "1 [(0, 3), 'NW', -1.0, (0, 2), 'N']\n",
      "1\n",
      "2 [(3, 0), 'SE', -1.0, (4, 1), 'NE']\n",
      "2 [(0, 5), 'NE', -1.0, (0, 6), 'SW']\n",
      "2\n",
      "3 [(3, 0), 'NW', -1.0, (2, 0), 'SW']\n",
      "3 [(0, 4), 'NE', -1.0, (0, 5), 'SW']\n",
      "3\n",
      "4 [(3, 0), 'NE', -1.0, (2, 1), 'SW']\n",
      "4 [(2, 2), 'W', -1.0, (2, 1), 'SW']\n",
      "4 [(1, 0), 'E', -1.0, (1, 1), 'SW']\n",
      "4 [(0, 3), 'S', -1.0, (0, 3), 'SW']\n",
      "4 [(0, 3), 'NE', -1.0, (0, 4), 'SW']\n",
      "4\n",
      "5 [(3, 0), 'S', -1.0, (4, 0), 'SW']\n",
      "5\n",
      "6 [(3, 0), 'W', -1.0, (3, 0), 'SW']\n",
      "6 [(0, 5), 'SW', -1.0, (0, 4), 'SW']\n",
      "6 [(2, 0), 'S', -1.0, (3, 0), 'SW']\n",
      "6 [(0, 1), 'N', -1.0, (0, 1), 'SW']\n",
      "6 [(0, 8), 'SW', -1.0, (0, 7), 'SW']\n",
      "6 [(5, 3), 'SW', -1.0, (6, 2), 'SW']\n",
      "6\n",
      "7 [(3, 0), 'S', -1.0, (4, 0), 'SW']\n",
      "7 [(1, 9), 'NE', -1.0, (0, 9), 'SW']\n",
      "7 [(1, 2), 'SE', -1.0, (1, 3), 'SW']\n",
      "7 [(0, 8), 'NE', -1.0, (0, 9), 'SW']\n",
      "7 [(5, 1), 'NW', -1.0, (4, 0), 'SW']\n",
      "7 [(1, 1), 'SE', -1.0, (2, 2), 'SW']\n",
      "7 [(0, 7), 'NE', -1.0, (0, 8), 'SW']\n",
      "7 [(0, 3), 'W', -1.0, (0, 2), 'SW']\n",
      "7 [(5, 0), 'W', -1.0, (5, 0), 'SW']\n",
      "7 [(0, 7), 'NE', -1.0, (0, 8), 'SW']\n",
      "7 [(3, 1), 'N', -1.0, (2, 1), 'SW']\n",
      "7 [(0, 5), 'E', -1.0, (0, 6), 'SW']\n",
      "7 [(3, 3), 'SW', -1.0, (4, 2), 'SW']\n",
      "7\n",
      "8 [(3, 0), 'NE', -1.0, (2, 1), 'SW']\n",
      "8 [(3, 0), 'NW', -1.0, (2, 0), 'SW']\n",
      "8 [(0, 3), 'N', -1.0, (0, 3), 'SW']\n",
      "8\n",
      "9 [(3, 0), 'N', -1.0, (2, 0), 'SW']\n",
      "9 [(6, 2), 'SW', -1.0, (6, 1), 'SW']\n",
      "9 [(0, 8), 'SE', -1.0, (1, 9), 'SW']\n",
      "9 [(2, 0), 'SW', -1.0, (3, 0), 'SW']\n",
      "9 [(4, 2), 'E', -1.0, (3, 3), 'SW']\n",
      "9 [(5, 1), 'E', -1.0, (5, 2), 'SW']\n",
      "9 [(1, 1), 'SE', -1.0, (2, 2), 'SW']\n",
      "9 [(0, 0), 'N', -1.0, (0, 0), 'SW']\n",
      "9\n",
      "10 [(3, 0), 'SW', -1.0, (4, 0), 'SW']\n",
      "10 [(6, 1), 'N', -1.0, (5, 1), 'SW']\n",
      "10 [(1, 3), 'E', -1.0, (0, 4), 'SW']\n",
      "10\n",
      "11 [(3, 0), 'S', -1.0, (4, 0), 'SW']\n",
      "11 [(0, 4), 'SW', -1.0, (0, 3), 'SW']\n",
      "11 [(1, 2), 'W', -1.0, (1, 1), 'SW']\n",
      "11 [(1, 0), 'E', -1.0, (1, 1), 'SW']\n",
      "11\n",
      "12 [(3, 0), 'NW', -1.0, (2, 0), 'SW']\n",
      "12 [(2, 1), 'SW', -1.0, (3, 0), 'SW']\n",
      "12\n",
      "13 [(3, 0), 'SE', -1.0, (4, 1), 'SW']\n",
      "13\n",
      "14 [(3, 0), 'NW', -1.0, (2, 0), 'SW']\n",
      "14 [(1, 1), 'SW', -1.0, (2, 0), 'SW']\n",
      "14 [(1, 0), 'SW', -1.0, (2, 0), 'SW']\n",
      "14 [(0, 5), 'W', -1.0, (0, 4), 'SW']\n",
      "14 [(3, 0), 'W', -1.0, (3, 0), 'SW']\n",
      "14 [(3, 1), 'NE', -1.0, (2, 2), 'SW']\n",
      "14 [(3, 2), 'SE', -1.0, (3, 3), 'SW']\n",
      "14 [(0, 3), 'S', -1.0, (0, 3), 'SW']\n",
      "14 [(0, 4), 'SW', -1.0, (0, 3), 'SW']\n",
      "14 [(0, 5), 'SE', -1.0, (0, 6), 'SW']\n",
      "14 [(0, 6), 'SW', -1.0, (0, 5), 'SW']\n",
      "14 [(4, 1), 'E', -1.0, (4, 2), 'SW']\n",
      "14 [(0, 0), 'N', -1.0, (0, 0), 'SW']\n",
      "14 [(3, 1), 'NE', -1.0, (2, 2), 'SW']\n",
      "14 [(0, 0), 'NE', -1.0, (0, 1), 'SW']\n",
      "14 [(3, 1), 'N', -1.0, (2, 1), 'SW']\n",
      "14 [(0, 7), 'W', -1.0, (0, 6), 'SW']\n",
      "14 [(1, 2), 'S', -1.0, (2, 2), 'SW']\n",
      "14 [(4, 0), 'E', -1.0, (4, 1), 'SW']\n",
      "14 [(1, 1), 'NW', -1.0, (0, 0), 'SW']\n",
      "14 [(2, 1), 'NE', -1.0, (1, 2), 'SW']\n",
      "14 [(2, 2), 'W', -1.0, (2, 1), 'SW']\n",
      "14 [(0, 5), 'W', -1.0, (0, 4), 'SW']\n",
      "14 [(6, 0), 'NE', -1.0, (5, 1), 'SW']\n",
      "14 [(4, 2), 'N', -1.0, (3, 2), 'SW']\n",
      "14 [(6, 1), 'NW', -1.0, (5, 0), 'SW']\n",
      "14 [(3, 0), 'SE', -1.0, (4, 1), 'SW']\n",
      "14 [(2, 1), 'NE', -1.0, (1, 2), 'SW']\n",
      "14 [(5, 0), 'NW', -1.0, (4, 0), 'SW']\n",
      "14 [(2, 0), 'SW', -1.0, (3, 0), 'SW']\n",
      "14 [(1, 2), 'NE', -1.0, (0, 3), 'SW']\n",
      "14 [(0, 3), 'W', -1.0, (0, 2), 'SW']\n",
      "14\n",
      "15 [(3, 0), 'NW', -1.0, (2, 0), 'SW']\n",
      "15 [(4, 0), 'S', -1.0, (5, 0), 'SW']\n",
      "15 [(0, 5), 'N', -1.0, (0, 5), 'SW']\n",
      "15 [(0, 5), 'SW', -1.0, (0, 4), 'SW']\n",
      "15 [(6, 2), 'N', -1.0, (5, 2), 'SW']\n",
      "15 [(6, 1), 'S', -1.0, (6, 1), 'SW']\n",
      "15 [(0, 4), 'NE', -1.0, (0, 5), 'SW']\n",
      "15 [(0, 4), 'SW', -1.0, (0, 3), 'SW']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-e636361c43df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mnext_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_next_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mnext_action\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_next_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'optimal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mget_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mtrain_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mget_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \"\"\"\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   3631\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3632\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 3633\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 766\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 964\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    965\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1014\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Representation of wind for each column\n",
    "wind = np.array([0, 0, 0, 1, 1, 1, 2, 2, 1, 0])\n",
    "\n",
    "num_episodes = 2000\n",
    "n, m = 7, 10\n",
    "initial_state = (3, 0)\n",
    "goal_state = (3, 7)\n",
    "\n",
    "rewards = np.zeros((n,m)) - 1\n",
    "rewards[goal_state] = 1\n",
    "\n",
    "# Actions\n",
    "actions = ['N', 'S', 'W', 'E', 'NW', 'NE', 'SW', 'SE']\n",
    "action_idx = {action:idx for idx,action in enumerate(actions)}\n",
    "action_effect = {\n",
    "    'N': [-1, 0],\n",
    "    'S': [1, 0],\n",
    "    'W': [0, -1],\n",
    "    'E': [0, 1],\n",
    "    'NW': [-1, -1],\n",
    "    'NE': [-1, 1],\n",
    "    'SW': [1, -1],\n",
    "    'SE': [1, 1],\n",
    "}\n",
    "\n",
    "learning_rate = 0.05\n",
    "\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, n * m))\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None, 8))\n",
    "W = tf.Variable(initial_value=tf.truncated_normal(shape=(n * m, 8)))\n",
    "Q = tf.matmul(X, W)\n",
    "#h1 = tf.contrib.layers.fully_connected(X, 50)\n",
    "#Q = tf.contrib.layers.fully_connected(h1, 1, activation_fn=None)\n",
    "mse = tf.reduce_mean(tf.square(y - Q))# * 1.0\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(mse)\n",
    "    \n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "    \n",
    "\n",
    "#Policy implicitly represented in the Q values\n",
    "def get_features(state):\n",
    "    features = np.zeros((n * m))\n",
    "    features[state[0] * m + state[1]] = 1\n",
    "    return features\n",
    "\n",
    "def get_next_action(Q, state, mode='epsilon_greedy', epsilon = 0.1):\n",
    "    features = np.array([get_features(state)])\n",
    "    q_values = Q.eval(feed_dict={X: features})\n",
    "    if mode == 'epsilon_greedy' and np.random.random_sample() < epsilon:\n",
    "        a = actions[np.random.randint(0, len(actions))]\n",
    "    else:\n",
    "        a = actions[np.argmax(q_values)]\n",
    "    return a, q_values\n",
    "\n",
    "def get_next_state(state, action):\n",
    "    next_state = np.sum([state, action_effect[action]], axis = 0)\n",
    "    next_state[0] = min(max(next_state[0], 0), n-1)\n",
    "    next_state[1] = min(max(next_state[1], 0), m-1)\n",
    "    next_state[0] -= wind[next_state[1]]\n",
    "    next_state[0] = min(max(next_state[0], 0), n-1)\n",
    "    return tuple(next_state)\n",
    "\n",
    "def perform_optimal_policy(Q):\n",
    "    s = initial_state\n",
    "    i = 0\n",
    "    grid = np.zeros((n,m))\n",
    "    grid[s] = 1\n",
    "    while s!=goal_state and i < 100 :\n",
    "        a = get_next_action(Q, s, 'optimal')\n",
    "        print('State: ', s)\n",
    "        print('Action: ', a)\n",
    "        print('-----')\n",
    "        s = get_next_state(s, a)\n",
    "        grid[s]=1\n",
    "        i+=1\n",
    "    print(grid)\n",
    "\n",
    "\n",
    "num_episodes = 2000\n",
    "epsilon = 1.0\n",
    "\n",
    "episode_tenth = np.ceil(num_episodes/10)\n",
    "for episode in range(num_episodes):\n",
    "    state = initial_state\n",
    "    i=0\n",
    "    while state!=goal_state:\n",
    "        action, Q_values = get_next_action(Q=Q, state=state, mode='epsilon_greedy', epsilon=epsilon)\n",
    "        next_state = get_next_state(state=state, action=action)\n",
    "        max_next_Q = np.max(Q.eval(feed_dict={X: np.array([get_features(next_state)])}))\n",
    "        Q_values[0][action_idx[action]] = rewards[state] + max_next_Q\n",
    "        train_op.run(feed_dict={X: np.array([get_features(state)]), y: Q_values})\n",
    "        if i % 10000 == 0:# or next_action!='N':\n",
    "            print(episode, [state, action, rewards[state], next_state, max_next_Q])\n",
    "        i+=1\n",
    "        state = next_state\n",
    "    epsilon *= 0.99\n",
    "    if episode % episode_tenth == 0 or True:\n",
    "        print(episode)\n",
    "print(episode)\n",
    "\n",
    "perform_optimal_policy(Q)\n",
    "\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
