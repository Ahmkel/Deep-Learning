{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains my implementation of the Convolutional LSTM cells, and a toy problem of counting the number of \"1\"s in a binary string where the input is in the form of images containing \"0\" or \"1\".\n",
    "\n",
    "Note: for this simple example there is only 1 image for each of the two values so we are not fully utilizing the convolutional aspect of the network, but it acts as a proof of concept that the implementation works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "from functools import reduce\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "from scipy.misc import imread\n",
    "\n",
    "img0 = np.reshape(1.0 - imread('./binary_pics/0.png', flatten=True)/255, newshape=(28, 28, 1,))\n",
    "img1 = np.reshape(1.0 - imread('./binary_pics/1.png', flatten=True)/255, newshape=(28, 28, 1,))\n",
    "\n",
    "train_input = ['{0:020b}'.format(i) for i in range(2**20)]\n",
    "shuffle(train_input)\n",
    "#train_input = train_input[:101000]\n",
    "train_output = np.zeros((len(train_input), 21))\n",
    "train_output[range(len(train_output)), [reduce(lambda x, y: int(x) + int(y), i) for i in train_input]] = 1\n",
    "train_input = [map(int,i) for i in train_input]\n",
    "ti = []\n",
    "for idx, train_instance in enumerate(train_input):\n",
    "    temp_arr = []\n",
    "    for j in train_instance:\n",
    "        temp_arr.append(img0 if j == 0 else img1)\n",
    "    ti.append(temp_arr)\n",
    "train_input = np.array(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_EXAMPLES = 1000\n",
    "train_X = train_input[:NUM_EXAMPLES]\n",
    "train_y = train_output[:NUM_EXAMPLES]\n",
    "test_X = train_input[NUM_EXAMPLES:]\n",
    "test_y = train_output[NUM_EXAMPLES:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# Define required layers\n",
    "def conv_relu(inputs, kernel_shape, name, add_bias=True, padding='SAME', data_format='NHWC'):\n",
    "    with tf.variable_scope(name):\n",
    "        weights = tf.get_variable(dtype=tf.float32, shape=kernel_shape, initializer=tf.contrib.layers.xavier_initializer(), name='weights')\n",
    "        x = tf.nn.conv2d(inputs, filter=weights, strides=(1,1,1,1,), padding=padding, data_format=data_format)\n",
    "        if add_bias:\n",
    "            biases = tf.get_variable(dtype=tf.float32, shape=(1, 1, 1, kernel_shape[-1],), initializer=tf.constant_initializer(0.0), name='biases')\n",
    "            x = x + biases\n",
    "        #return tf.nn.relu(x)\n",
    "        return tf.maximum(0.02 * x, x)\n",
    "    \n",
    "def max_pool(input, data_format='NHWC'):\n",
    "    return tf.nn.max_pool(input, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1), padding='SAME', data_format=data_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyConvLSTMCell(tf.contrib.rnn.RNNCell):\n",
    "    def __init__(self, input_shape, kernel_shape, n_filters, forget_bias=1.0):\n",
    "        super(MyConvLSTMCell, self).__init__()\n",
    "        self._size = tf.TensorShape([input_shape, input_shape, n_filters])\n",
    "        self._kernel_shape = kernel_shape\n",
    "        self._n_filters = n_filters\n",
    "        self._forget_bias = forget_bias\n",
    "    \n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return tf.nn.rnn_cell.LSTMStateTuple(self._size, self._size)\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._size\n",
    "    \n",
    "    def call(self, inputs, state):\n",
    "        c, h = state\n",
    "        \n",
    "        n_channels = inputs.shape[3] + self._n_filters\n",
    "        n_filters = 4 * self._n_filters\n",
    "        concat = conv_relu(tf.concat(values=[inputs, h], axis=3), (self._kernel_shape, self._kernel_shape, n_channels, n_filters), name='LSTMConvRelu')\n",
    "        i, f, o, c_in = tf.split(value=concat, num_or_size_splits=4, axis=3)\n",
    "        i, f, o, c_in = tf.sigmoid(i), tf.sigmoid(f + self._forget_bias), tf.sigmoid(o), tf.tanh(c_in)\n",
    "        c_new = c * f + i * c_in\n",
    "        h_new = o * tf.tanh(c_new)\n",
    "\n",
    "        state_new = tf.nn.rnn_cell.LSTMStateTuple(c_new, h_new)\n",
    "        return h_new, state_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, 20, 28, 28, 1,))\n",
    "y = tf.placeholder(dtype=tf.int32, shape=(None, 21,))\n",
    "\n",
    "with tf.name_scope('Network'):\n",
    "    # Reshape\n",
    "    X_preprocess = tf.reshape(X, shape=(-1, 28, 28, 1))\n",
    "    # Conv1\n",
    "    X_preprocess = conv_relu(X_preprocess, kernel_shape=(3, 3, 1, 10), name='ConvRelu1')\n",
    "    # Maxpool1\n",
    "    X_preprocess = max_pool(X_preprocess)\n",
    "    # Conv2\n",
    "    X_preprocess = conv_relu(X_preprocess, kernel_shape=(3, 3, 10, 20), name='ConvRelu2')\n",
    "    # Maxpool2\n",
    "    X_preprocess = max_pool(X_preprocess)\n",
    "    # Reshape back\n",
    "    X_preprocess = tf.reshape(X_preprocess, shape=(-1, 20, 7, 7, 20,))\n",
    "\n",
    "    #LSTM (Conv2)\n",
    "    cell = MyConvLSTMCell(7, 3, 30)\n",
    "    val, state = tf.nn.dynamic_rnn(cell, X_preprocess, dtype=tf.float32)\n",
    "\n",
    "    # Switch dimensions to get time dimension in beginning\n",
    "    val = tf.transpose(val, [1, 0, 2, 3, 4])\n",
    "    # Gather the outputs of the last cell only containing the count of all ones\n",
    "    last = tf.gather(val, 19)\n",
    "\n",
    "    # Conv3\n",
    "    X_postprocess = conv_relu(last, kernel_shape=(7, 7, 30, 1000), padding='VALID', name='ConvRelu3')\n",
    "    # Conv4\n",
    "    X_postprocess = conv_relu(X_postprocess, kernel_shape=(1, 1, 1000, 400), name='ConvRelu4')\n",
    "    # Conv5\n",
    "    X_postprocess = conv_relu(X_postprocess, kernel_shape=(1, 1, 400, 21), name='ConvRelu5')\n",
    "    logits = tf.reshape(X_postprocess, shape=(-1, 21,))\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\n",
    "    train_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope('eval'):\n",
    "    output = tf.argmax(logits, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(output, tf.argmax(y, 1)), tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: accuracy: 0.162000, 2.979653\n",
      "1: accuracy: 0.162000, 2.870096\n",
      "2: accuracy: 0.162000, 2.706068\n",
      "3: accuracy: 0.190000, 2.590760\n",
      "4: accuracy: 0.158000, 2.580671\n",
      "5: accuracy: 0.155000, 2.553548\n",
      "6: accuracy: 0.166000, 2.554590\n",
      "7: accuracy: 0.196000, 2.539707\n",
      "8: accuracy: 0.215000, 2.528972\n",
      "9: accuracy: 0.216000, 2.517405\n",
      "10: accuracy: 0.222000, 2.476867\n",
      "11: accuracy: 0.209000, 2.360111\n",
      "12: accuracy: 0.231000, 2.227421\n",
      "13: accuracy: 0.250000, 2.169732\n",
      "14: accuracy: 0.274000, 2.102192\n",
      "15: accuracy: 0.339000, 1.997261\n",
      "16: accuracy: 0.444000, 1.836992\n",
      "17: accuracy: 0.453000, 1.666197\n",
      "18: accuracy: 0.486000, 1.552577\n",
      "19: accuracy: 0.585000, 1.453385\n",
      "20: accuracy: 0.709000, 1.362246\n",
      "21: accuracy: 0.765000, 1.277719\n",
      "22: accuracy: 0.795000, 1.199731\n",
      "23: accuracy: 0.813000, 1.122648\n",
      "24: accuracy: 0.845000, 1.046429\n",
      "25: accuracy: 0.869000, 0.966905\n",
      "26: accuracy: 0.891000, 0.894784\n",
      "27: accuracy: 0.896000, 0.832809\n",
      "28: accuracy: 0.904000, 0.773542\n",
      "29: accuracy: 0.911000, 0.718065\n",
      "30: accuracy: 0.914000, 0.666219\n",
      "31: accuracy: 0.918000, 0.622806\n",
      "32: accuracy: 0.920000, 0.581281\n",
      "33: accuracy: 0.939000, 0.546167\n",
      "34: accuracy: 0.936000, 0.516233\n",
      "35: accuracy: 0.944000, 0.488314\n",
      "36: accuracy: 0.953000, 0.462262\n",
      "37: accuracy: 0.965000, 0.437611\n",
      "38: accuracy: 0.966000, 0.416126\n",
      "39: accuracy: 0.968000, 0.396474\n",
      "40: accuracy: 0.966000, 0.377740\n",
      "41: accuracy: 0.966000, 0.356167\n",
      "42: accuracy: 0.966000, 0.333747\n",
      "43: accuracy: 0.967000, 0.310703\n",
      "44: accuracy: 0.967000, 0.284289\n",
      "45: accuracy: 0.970000, 0.254702\n",
      "46: accuracy: 0.971000, 0.226621\n",
      "47: accuracy: 0.972000, 0.205784\n",
      "48: accuracy: 0.972000, 0.192562\n",
      "49: accuracy: 0.972000, 0.179623\n",
      "50: accuracy: 0.974000, 0.168548\n",
      "51: accuracy: 0.974000, 0.158029\n",
      "52: accuracy: 0.976000, 0.147368\n",
      "53: accuracy: 0.980000, 0.137725\n",
      "54: accuracy: 0.980000, 0.128973\n",
      "55: accuracy: 0.982000, 0.121009\n",
      "56: accuracy: 0.985000, 0.113706\n",
      "57: accuracy: 0.985000, 0.106559\n",
      "58: accuracy: 0.986000, 0.099492\n",
      "59: accuracy: 0.987000, 0.092976\n",
      "60: accuracy: 0.989000, 0.087326\n",
      "61: accuracy: 0.989000, 0.081872\n",
      "62: accuracy: 0.990000, 0.077106\n",
      "63: accuracy: 0.989000, 0.072842\n",
      "64: accuracy: 0.990000, 0.069256\n",
      "65: accuracy: 0.990000, 0.065896\n",
      "66: accuracy: 0.990000, 0.062916\n",
      "67: accuracy: 0.990000, 0.060096\n",
      "68: accuracy: 0.990000, 0.057540\n",
      "69: accuracy: 0.990000, 0.055143\n",
      "70: accuracy: 0.990000, 0.052848\n",
      "71: accuracy: 0.991000, 0.050661\n",
      "72: accuracy: 0.992000, 0.048598\n",
      "73: accuracy: 0.992000, 0.046749\n",
      "74: accuracy: 0.993000, 0.045045\n",
      "75: accuracy: 0.993000, 0.043403\n",
      "76: accuracy: 0.993000, 0.041723\n",
      "77: accuracy: 0.993000, 0.040177\n",
      "78: accuracy: 0.993000, 0.038806\n",
      "79: accuracy: 0.993000, 0.037487\n",
      "80: accuracy: 0.993000, 0.036136\n",
      "81: accuracy: 0.995000, 0.034906\n",
      "82: accuracy: 0.996000, 0.033722\n",
      "83: accuracy: 0.996000, 0.032606\n",
      "84: accuracy: 0.996000, 0.031536\n",
      "85: accuracy: 0.996000, 0.030553\n",
      "86: accuracy: 0.996000, 0.029596\n",
      "87: accuracy: 0.997000, 0.028659\n",
      "88: accuracy: 0.997000, 0.027749\n",
      "89: accuracy: 0.997000, 0.026904\n",
      "90: accuracy: 0.997000, 0.026117\n",
      "91: accuracy: 0.997000, 0.025374\n",
      "92: accuracy: 0.997000, 0.024665\n",
      "93: accuracy: 0.997000, 0.023933\n",
      "94: accuracy: 0.997000, 0.023210\n",
      "95: accuracy: 0.997000, 0.022567\n",
      "96: accuracy: 0.997000, 0.021935\n",
      "97: accuracy: 0.997000, 0.021364\n",
      "98: accuracy: 0.997000, 0.020828\n",
      "99: accuracy: 0.997000, 0.020250\n",
      "('Final training accuracy: ', [0.9970001, 0.020250188])\n",
      "('Final testing accuracy: ', 0.99684006)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./counting-conv-lstm.ckpt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "num_epochs = 100\n",
    "batch_size = 200\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    for j in range(NUM_EXAMPLES//batch_size):\n",
    "        sess.run(train_op, feed_dict={X: train_X[j*batch_size:(j+1)*batch_size], y: train_y[j*batch_size:(j+1)*batch_size]})\n",
    "    acc, l = sess.run([accuracy, loss], feed_dict={X: train_X, y: train_y})\n",
    "    print('%d: accuracy: %f, %f' % (i, acc, l))\n",
    "\n",
    "print('Final training accuracy: ', sess.run([accuracy, loss], feed_dict={X: train_X, y: train_y}))\n",
    "testing_accuracies = []\n",
    "for i in range(100):\n",
    "    testing_accuracies.append(accuracy.eval(feed_dict={X: test_X[i*1000:(i+1)*1000], y: test_y[i*1000:(i+1)*1000]}))\n",
    "print('Final testing accuracy: ' , np.mean(testing_accuracies))\n",
    "saver.save(sess, './counting-conv-lstm.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "('Final testing accuracy: ', 0.99663562)\n"
     ]
    }
   ],
   "source": [
    "train_input = ['{0:020b}'.format(i) for i in range(2**20)]\n",
    "shuffle(train_input)\n",
    "train_output = np.zeros((len(train_input), 21))\n",
    "train_output[range(len(train_output)), [reduce(lambda x, y: int(x) + int(y), i) for i in train_input]] = 1\n",
    "train_input = [map(int,i) for i in train_input]\n",
    "testing_accuracies = []\n",
    "for i in range(len(train_input) / 1000):\n",
    "    ti = []\n",
    "    for idx, train_instance in enumerate(train_input[i*1000:(i+1)*1000]):\n",
    "        temp_arr = []\n",
    "        for j in train_instance:\n",
    "            temp_arr.append(img0 if j == 0 else img1)\n",
    "        ti.append(temp_arr)\n",
    "    test_X = np.array(ti)\n",
    "    test_y = train_output[i*1000:(i+1)*1000]\n",
    "    testing_accuracies.append(accuracy.eval(feed_dict={X: test_X, y: test_y}))\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "print('Final testing accuracy: ' , np.mean(testing_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep(code):\n",
    "    input = [[]]\n",
    "    count = [0]\n",
    "    for i in code:\n",
    "        input[0].append(img0 if i == '0' else img1)\n",
    "        count[0] += int(i)\n",
    "    return np.array(input), count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred(code):\n",
    "    inputs, target = prep(code)\n",
    "    f, axs = plt.subplots(1, 20, figsize=(15, 15))\n",
    "    for i in range(len(code)):\n",
    "        axs[i].imshow(inputs[0, i].reshape((28, 28)))\n",
    "        axs[i].axis('off')\n",
    "    print('Real: ', target)\n",
    "    print('Predicted: ', np.argmax(logits.eval(feed_dict={X: inputs}), 1)[0])\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Real: ', [15])\n",
      "('Predicted: ', 15)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAABGCAYAAAC9rWfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc6a84a5f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred('01110111100101111111')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
