{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a solution for the CartPole problem using Actor-Critic policy gradient method where the critic predicts the state value function, the updates are based on TD(0), and the advantage function is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$A^{\\pi_\\theta}(s,a) = r + \\gamma V_v(S_{t+1}) - V_v(S_t)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Math\n",
    "display(Math(r'A^{\\pi_\\theta}(s,a) = r + \\gamma V_v(S_{t+1}) - V_v(S_t)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-04 04:31:56,442] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 99, Mean reward: 18\n",
      "Episode: 199, Mean reward: 20\n",
      "Episode: 299, Mean reward: 27\n",
      "Episode: 399, Mean reward: 34\n",
      "Episode: 499, Mean reward: 44\n",
      "Episode: 599, Mean reward: 50\n",
      "Episode: 699, Mean reward: 54\n",
      "Episode: 799, Mean reward: 64\n",
      "Episode: 899, Mean reward: 83\n",
      "Episode: 999, Mean reward: 129\n",
      "Episode: 1099, Mean reward: 180\n",
      "Episode: 1199, Mean reward: 171\n",
      "Episode: 1299, Mean reward: 127\n",
      "Episode: 1399, Mean reward: 182\n",
      "Mean reward:  88.1259568546\n",
      "Max 100 rewards mean:  199.55\n",
      "Max 100 rewards from episode: 1337, to episode: 1436\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEBHJYv8fbnHOgR/htcAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd4ad148438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Play 20 times with optimal policy\n",
      "Iteration: 0, Total Reward: 200\n",
      "Iteration: 1, Total Reward: 200\n",
      "Iteration: 2, Total Reward: 200\n",
      "Iteration: 3, Total Reward: 200\n",
      "Iteration: 4, Total Reward: 200\n",
      "Iteration: 5, Total Reward: 200\n",
      "Iteration: 6, Total Reward: 200\n",
      "Iteration: 7, Total Reward: 200\n",
      "Iteration: 8, Total Reward: 200\n",
      "Iteration: 9, Total Reward: 200\n",
      "Iteration: 10, Total Reward: 200\n",
      "Iteration: 11, Total Reward: 200\n",
      "Iteration: 12, Total Reward: 200\n",
      "Iteration: 13, Total Reward: 200\n",
      "Iteration: 14, Total Reward: 200\n",
      "Iteration: 15, Total Reward: 200\n",
      "Iteration: 16, Total Reward: 200\n",
      "Iteration: 17, Total Reward: 200\n",
      "Iteration: 18, Total Reward: 200\n",
      "Iteration: 19, Total Reward: 200\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "max_num_episodes = 10000\n",
    "checkpoint = 100\n",
    "\n",
    "actor_learning_rate = 0.01\n",
    "critic_learning_rate = 0.001\n",
    "\n",
    "decay = 0.99\n",
    " \n",
    "class Actor:\n",
    "    def __init__(self):\n",
    "        with tf.variable_scope('Actor'):\n",
    "            self._X = tf.placeholder(dtype=tf.float32, shape=(None, 4))\n",
    "            self._rewards = tf.placeholder(dtype=tf.float32, shape=(None,1))\n",
    "            self._logits = tf.contrib.layers.fully_connected(self._X, 2, activation_fn=None)\n",
    "            self._policy = tf.contrib.layers.softmax(self._logits)\n",
    "            self._actions = tf.placeholder(dtype=tf.float32, shape=(None,2))\n",
    "            self._delta = tf.log(tf.reduce_sum(tf.mul(self._policy, self._actions), axis=1)) * self._rewards\n",
    "            self._train_step = tf.train.AdamOptimizer(learning_rate=actor_learning_rate).minimize(-1 * self._delta)\n",
    "\n",
    "    def predict_policy(self, state):\n",
    "        return self._policy.eval(feed_dict={self._X: state.reshape((-1, 4))})\n",
    "    \n",
    "    def train_policy(self, states, actions, rewards):\n",
    "        actions_mask = np.zeros((len(actions), 2))\n",
    "        actions_mask[range(len(actions)), actions] = 1\n",
    "        return self._train_step.run(feed_dict={self._X: states.reshape((-1, 4)), self._actions: actions_mask, self._rewards: rewards.reshape((-1,1))})\n",
    "\n",
    "class Critic:\n",
    "    def __init__(self):\n",
    "        with tf.variable_scope('Critic'):\n",
    "            self._X = tf.placeholder(dtype=tf.float32, shape=(None, 4))\n",
    "            self._y = tf.placeholder(dtype=tf.float32, shape=(None, 1))\n",
    "            self._net = tf.contrib.layers.fully_connected(self._X, 15)\n",
    "            self._Q = tf.contrib.layers.fully_connected(self._net, 1, activation_fn=None)\n",
    "            self._mse = tf.contrib.losses.mean_squared_error(self._y, self._Q)\n",
    "            self._train_step = tf.train.AdamOptimizer(learning_rate=critic_learning_rate).minimize(self._mse)\n",
    "\n",
    "    def predict_Q(self, state):\n",
    "        return self._Q.eval(feed_dict={self._X: state.reshape((-1, 4))})\n",
    "    \n",
    "    def train_Q(self, states, targets):\n",
    "        return self._train_step.run(feed_dict={self._X: states.reshape((-1, 4)), self._y: targets.reshape((-1, 1))})\n",
    "        \n",
    "def stats(rewards):\n",
    "    print(\"Mean reward: \", np.mean(rewards))\n",
    "    rewards_100 = []\n",
    "    for i in range(100, len(rewards) + 1):\n",
    "        rewards_100.append(np.mean(rewards[i-100:i]))\n",
    "    print(\"Max 100 rewards mean: \", np.max(rewards_100))\n",
    "    re = np.argmax(rewards_100)\n",
    "    print(\"Max 100 rewards from episode: %d, to episode: %d\" % (re, re + 99))\n",
    "    plt.plot(rewards_100)\n",
    "    plt.show()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "all_rewards = []\n",
    "\n",
    "actor = Actor()\n",
    "critic = Critic()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "\n",
    "for episode in range(max_num_episodes):\n",
    "    state = env.reset()\n",
    "    epsilon = 1./((episode/50) + 10)\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    experiences = []\n",
    "    while not done:\n",
    "        action = np.random.choice(range(2), p=actor.predict_policy(state)[0])\n",
    "\n",
    "        # Perform action\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        # Append final reward for each episode\n",
    "        episode_reward += reward\n",
    "\n",
    "        # Change 0 reward to -1 to learn more from punishment\n",
    "        if reward == 0:\n",
    "            reward = -1\n",
    "\n",
    "        # Save experience\n",
    "        experiences.append([state, action, reward, next_state, done])\n",
    "\n",
    "        # Switch to next state\n",
    "        state = next_state\n",
    "        \n",
    "    states = np.vstack([x[0] for x in experiences])\n",
    "    actions = np.array([x[1] for x in experiences])\n",
    "    rewards = np.array([x[2] for x in experiences])\n",
    "    next_states = np.vstack([x[3] for x in experiences])\n",
    "    episode_done = np.array([x[4] for x in experiences])\n",
    "\n",
    "    curr_v = critic.predict_Q(states)\n",
    "    next_v = critic.predict_Q(next_states)\n",
    "    bootstrapped_value = rewards + decay * next_v[:, 0] * ~episode_done\n",
    "    actor.train_policy(states, actions, bootstrapped_value - curr_v[:, 0])\n",
    "    critic.train_Q(states, bootstrapped_value)\n",
    "            \n",
    "\n",
    "    if (episode + 1) % checkpoint == 0:\n",
    "        print(\"Episode: %d, Mean reward: %d\" % (episode, np.mean(all_rewards[-100:])))\n",
    "    \n",
    "    all_rewards.append(episode_reward)\n",
    "    \n",
    "    if np.mean(all_rewards[-100:]) > 199.5:\n",
    "        break\n",
    "\n",
    "stats(all_rewards)\n",
    "\n",
    "print(\"Play 20 times with optimal policy\")\n",
    "for i in range(20):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        state, reward, done, _ = env.step(np.random.choice(range(2), p=actor.predict_policy(state)[0]))\n",
    "        total_reward += reward\n",
    "        env.render()\n",
    "    print(\"Iteration: %d, Total Reward: %d\" % (i, total_reward))\n",
    "    \n",
    "sess.close()\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
